{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = 'Downloads/dogs-vs-cats/train1' # uncompressed data stored\n",
    "base_dir = 'Downloads/cats_and_dogs_small'   # will be substitued to train, test, validation in this directory\n",
    "# os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "# os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "# os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "# os.mkdir(test_dir)\n",
    "\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "# os.mkdir(train_cats_dir)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "# os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "# os.mkdir(validation_cats_dir)\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "# os.mkdir(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "# os.mkdir(test_cats_dir)\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "# os.mkdir(test_dogs_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)  # copy from original to train\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ae9dba222136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr = 1e-4), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/syem/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.6878 - acc: 0.5562 - val_loss: 0.6454 - val_acc: 0.4975\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.6862 - acc: 0.5688 - val_loss: 0.7073 - val_acc: 0.5090\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr = 1e-4), metrics = ['acc'])\n",
    "\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,    # data transformation leading to more images\n",
    "                                  rotation_range = 40,\n",
    "                                  width_shift_range = 0.2,\n",
    "                                  height_shift_range = 0.2,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size = (150, 150),\n",
    "                                                   batch_size = 32,\n",
    "                                                   class_mode = 'binary')\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                       target_size = (150, 150),\n",
    "                                                       batch_size = 32,\n",
    "                                                       class_mode = 'binary')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = 5,\n",
    "                             epochs = 2,\n",
    "                             validation_data = validation_generator,\n",
    "                             validation_steps = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'conda clean --source-cache' is deprecated.\n",
      "    Use 'conda build purge-all' to remove source cache files.\n",
      "Cache location: /Users/syem/anaconda3/pkgs\n",
      "Will remove the following tarballs:\n",
      "\n",
      "/Users/syem/anaconda3/pkgs\n",
      "--------------------------\n",
      "clang_osx-64-4.0.1-h1ce6c1d_17.tar.bz2       145 KB\n",
      "clangxx-4.0.1-1.tar.bz2                      263 KB\n",
      "openssl-1.1.1b-h1de35cc_1.tar.bz2            3.5 MB\n",
      "pystan-2.17.1.0-py37h051e8ed_1004.tar.bz2    14.2 MB\n",
      "conda-4.7.12-py37_0.tar.bz2                  3.0 MB\n",
      "lunardate-0.2.0-py_0.tar.bz2                  21 KB\n",
      "convertdate-2.2.1-pyh9f0ad1d_0.tar.bz2        33 KB\n",
      "ipython-7.4.0-py37h39e3cac_0.tar.bz2         1.1 MB\n",
      "compiler-rt-4.0.1-hcfea43d_1.tar.bz2         1.2 MB\n",
      "clangxx_osx-64-4.0.1-h22b1bf0_17.tar.bz2     146 KB\n",
      "llvm-4.0.1-1.tar.bz2                       136.6 MB\n",
      "python_abi-3.7-1_cp37m.tar.bz2                 4 KB\n",
      "llvm-lto-tapi-4.0.1-1.tar.bz2               11.9 MB\n",
      "cctools-895-1.tar.bz2                        1.9 MB\n",
      "clang-4.0.1-1.tar.bz2                       73.9 MB\n",
      "holidays-0.10.2-pyh9f0ad1d_0.tar.bz2          59 KB\n",
      "conda-4.8.3-py37hc8dfbb8_1.tar.bz2           3.0 MB\n",
      "anaconda-2019.03-py37_0.tar.bz2               10 KB\n",
      "certifi-2019.3.9-py37_0.tar.bz2              155 KB\n",
      "ca-certificates-2019.1.23-0.tar.bz2          126 KB\n",
      "korean_lunar_calendar-0.2.1-pyh9f0ad1d_0.tar.bz2      10 KB\n",
      "fbprophet-0.5-py37h6de7cb9_0.tar.bz2         631 KB\n",
      "ld64-274.2-1.tar.bz2                         2.9 MB\n",
      "pymeeus-0.3.7-pyh9f0ad1d_0.tar.bz2           515 KB\n",
      "\n",
      "---------------------------------------------------\n",
      "Total:                                     255.1 MB\n",
      "\n",
      "Removed clang_osx-64-4.0.1-h1ce6c1d_17.tar.bz2\n",
      "Removed clangxx-4.0.1-1.tar.bz2\n",
      "Removed openssl-1.1.1b-h1de35cc_1.tar.bz2\n",
      "Removed pystan-2.17.1.0-py37h051e8ed_1004.tar.bz2\n",
      "Removed conda-4.7.12-py37_0.tar.bz2\n",
      "Removed lunardate-0.2.0-py_0.tar.bz2\n",
      "Removed convertdate-2.2.1-pyh9f0ad1d_0.tar.bz2\n",
      "Removed ipython-7.4.0-py37h39e3cac_0.tar.bz2\n",
      "Removed compiler-rt-4.0.1-hcfea43d_1.tar.bz2\n",
      "Removed clangxx_osx-64-4.0.1-h22b1bf0_17.tar.bz2\n",
      "Removed llvm-4.0.1-1.tar.bz2\n",
      "Removed python_abi-3.7-1_cp37m.tar.bz2\n",
      "Removed llvm-lto-tapi-4.0.1-1.tar.bz2\n",
      "Removed cctools-895-1.tar.bz2\n",
      "Removed clang-4.0.1-1.tar.bz2\n",
      "Removed holidays-0.10.2-pyh9f0ad1d_0.tar.bz2\n",
      "Removed conda-4.8.3-py37hc8dfbb8_1.tar.bz2\n",
      "Removed anaconda-2019.03-py37_0.tar.bz2\n",
      "Removed certifi-2019.3.9-py37_0.tar.bz2\n",
      "Removed ca-certificates-2019.1.23-0.tar.bz2\n",
      "Removed korean_lunar_calendar-0.2.1-pyh9f0ad1d_0.tar.bz2\n",
      "Removed fbprophet-0.5-py37h6de7cb9_0.tar.bz2\n",
      "Removed ld64-274.2-1.tar.bz2\n",
      "Removed pymeeus-0.3.7-pyh9f0ad1d_0.tar.bz2\n",
      "WARNING: /Users/syem/.conda/pkgs does not exist\n",
      "Cache location: /Users/syem/anaconda3/pkgs\n",
      "Will remove the following packages:\n",
      "/Users/syem/anaconda3/pkgs\n",
      "--------------------------\n",
      "\n",
      "conda-4.7.12-py37_0                         11.4 MB\n",
      "python_abi-3.7-1_cp37m                        10 KB\n",
      "anaconda-2019.03-py37_0                       57 KB\n",
      "ld64-274.2-1                                11.2 MB\n",
      "ca-certificates-2019.5.15-1                  239 KB\n",
      "openssl-1.1.1c-h1de35cc_1                    9.8 MB\n",
      "conda-4.7.11-py37_0                         11.4 MB\n",
      "clangxx-4.0.1-1                              2.2 MB\n",
      "certifi-2019.6.16-py37_1                     314 KB\n",
      "\n",
      "---------------------------------------------------\n",
      "Total:                                      46.5 MB\n",
      "\n",
      "removing conda-4.7.12-py37_0\n",
      "removing python_abi-3.7-1_cp37m\n",
      "removing anaconda-2019.03-py37_0\n",
      "removing ld64-274.2-1\n",
      "removing ca-certificates-2019.5.15-1\n",
      "removing openssl-1.1.1c-h1de35cc_1\n",
      "removing conda-4.7.11-py37_0\n",
      "removing clangxx-4.0.1-1\n",
      "removing certifi-2019.6.16-py37_1\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda clean -tipsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 25s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "# pretrained convet\n",
    "\n",
    "conv_base = VGG16(weights = 'imagenet',\n",
    "                 include_top = False,\n",
    "                 input_shape = (150, 150, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'Downloads/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape= (sample_count, 4, 4, 512))  # zeros will be filled with values extracted\n",
    "    labels = np.zeros(shape = (sample_count))\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                           target_size = (150, 150),      # data augmentation not used, no new data\n",
    "                                           batch_size = batch_size,\n",
    "                                           class_mode = 'binary')\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i+1) * batch_size] = features_batch # fill zeros with values\n",
    "        labels[i * batch_size: (i+1) * batch_size] = labels_batch\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "            \n",
    "    return features, labels\n",
    "        \n",
    "train_features, train_labels = extract_features(train_dir, 2000) # 2000 training, sample count\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000) # validation 1000\n",
    "test_features, test_labels = extract_features(test_dir, 1000) # testing 1000\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the data in (4,4,512) image data form before feeding it to dense layer\n",
    "train_features = np.reshape(train_features, (2000, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1000, 4 * 4 * 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.6179 - acc: 0.6515 - val_loss: 0.4486 - val_acc: 0.8360\n",
      "Epoch 2/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.4355 - acc: 0.7985 - val_loss: 0.3651 - val_acc: 0.8500\n",
      "Epoch 3/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3557 - acc: 0.8525 - val_loss: 0.3242 - val_acc: 0.8840\n",
      "Epoch 4/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.3183 - acc: 0.8680 - val_loss: 0.3004 - val_acc: 0.8810\n",
      "Epoch 5/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2879 - acc: 0.8850 - val_loss: 0.2816 - val_acc: 0.8930\n",
      "Epoch 6/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.2634 - acc: 0.8995 - val_loss: 0.2734 - val_acc: 0.8960\n",
      "Epoch 7/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.2479 - acc: 0.9080 - val_loss: 0.2726 - val_acc: 0.8940\n",
      "Epoch 8/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.2359 - acc: 0.9130 - val_loss: 0.2557 - val_acc: 0.8990\n",
      "Epoch 9/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.2193 - acc: 0.9205 - val_loss: 0.2541 - val_acc: 0.9000\n",
      "Epoch 10/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.2107 - acc: 0.9225 - val_loss: 0.2503 - val_acc: 0.8980\n",
      "Epoch 11/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.2045 - acc: 0.9265 - val_loss: 0.2598 - val_acc: 0.8910\n",
      "Epoch 12/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1927 - acc: 0.9305 - val_loss: 0.2469 - val_acc: 0.8990\n",
      "Epoch 13/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1839 - acc: 0.9305 - val_loss: 0.2443 - val_acc: 0.8980\n",
      "Epoch 14/30\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1729 - acc: 0.9400 - val_loss: 0.2400 - val_acc: 0.9030\n",
      "Epoch 15/30\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.1650 - acc: 0.9440 - val_loss: 0.2450 - val_acc: 0.9010\n",
      "Epoch 16/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1581 - acc: 0.9470 - val_loss: 0.2424 - val_acc: 0.9000\n",
      "Epoch 17/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1526 - acc: 0.9455 - val_loss: 0.2403 - val_acc: 0.9020\n",
      "Epoch 18/30\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.1450 - acc: 0.9505 - val_loss: 0.2357 - val_acc: 0.9050\n",
      "Epoch 19/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1376 - acc: 0.9515 - val_loss: 0.2358 - val_acc: 0.9030\n",
      "Epoch 20/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1376 - acc: 0.9550 - val_loss: 0.2381 - val_acc: 0.9030\n",
      "Epoch 21/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1260 - acc: 0.9610 - val_loss: 0.2423 - val_acc: 0.9030\n",
      "Epoch 22/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1202 - acc: 0.9595 - val_loss: 0.2359 - val_acc: 0.9010\n",
      "Epoch 23/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1205 - acc: 0.9590 - val_loss: 0.2360 - val_acc: 0.9060\n",
      "Epoch 24/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1115 - acc: 0.9625 - val_loss: 0.2374 - val_acc: 0.9040\n",
      "Epoch 25/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1055 - acc: 0.9665 - val_loss: 0.2421 - val_acc: 0.9040\n",
      "Epoch 26/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.1047 - acc: 0.9640 - val_loss: 0.2378 - val_acc: 0.9010\n",
      "Epoch 27/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.0983 - acc: 0.9705 - val_loss: 0.2374 - val_acc: 0.9030\n",
      "Epoch 28/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.0954 - acc: 0.9720 - val_loss: 0.2694 - val_acc: 0.8910\n",
      "Epoch 29/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.0969 - acc: 0.9690 - val_loss: 0.2444 - val_acc: 0.9070\n",
      "Epoch 30/30\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.0921 - acc: 0.9700 - val_loss: 0.2385 - val_acc: 0.9030\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation = 'relu', input_dim = 4 * 4 * 512))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = optimizers.RMSprop(lr = 2e-5), loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "history = model.fit(train_features, train_labels, epochs = 30, batch_size = 20, \n",
    "                    validation_data = (validation_features, validation_labels), )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwU9Z3/8deHkUMOAQVXBYZBRA2Mw+EEJWokHlxJ1BhUEBPRNUQ38Wd0NSFqPEiM2ZhsNI/ERNQ8dJVAXI2GGI1rErw2HgwqKrgK4XKA6MglNwzz+f3xrRl6enpmquegp4v38/Gox3RXfavqW93T7/72ty5zd0REJLna5boCIiLSuhT0IiIJp6AXEUk4Bb2ISMIp6EVEEk5BLyKScAp6yYqZHWlmW1poWd8zs1+3xLJak5k9bGa3tMJyXzKzqdHji83s6Thlm7CeFnvPJD8p6BPMzArNbEvK4Ga2NeX5Kdku092XuXvXlqifu3/f3S9viWXlO3d/0N3Ht8SyzKzczEanLLvF3jPJTwfkugLSetx9FVDzATczB4a6+9L65jGzAnffsy/qJyL7hlr0+7moW+KXZvZnM9sKnGJmZ5nZm2a22cxWmdn3UsofFX1hVD9/ycxuNbO/R+X/bGYHp5Y1s69GrcwKM5ueMu8PzOyBmGU7R3XdaGaLzWy6ma1oYLt+ES3nEzObb2afSVvv7Gh5m83sHTMbkTL9+JTtnw10rGcdB0bLPzZl3GFmtt3MDomGp6Jt2WBmfzSzPvUs6zIzey7l+Tgze8/MNpnZXYClTBtkZvPMbJ2ZfWxmD5lZ92jabOAI4OnoV9s1Gd6zvmb2pJmtN7MlZnZp3Ncmy9f5gKh77h/R9DIzOyKadpyZ/SWqwz/N7Nv1rUOaT0EvABcCtwLdgJeBLcBFQHfgi8BVZvaFRua/GPgXoAtwTdr0zwBHAWOBW81sUAPLqq/sDEKAFUXTLmpkm14FSoCDgUeB/zaz1MA+B3gI6AE8DfwcICrzB+A30bx/iMrW4e7bgSeAySmjLwD+6u7rCJ+ve4FCoD+wG7irkXpjZodGdZ4O9ALKgRNSiwA/AA4HBgNHAt+L6jQZWAOMd/eu7v6fGVbxO2A54fW8APixmZ2aMj3ja1OPhl7n64CJwLhoWZcBO6Ivpb8Af4y24WjguYZeE2kmd9ewnwyAA0eljXsY+E0j8/0CuCN6fFT4t6mZ9hIwPeX5/wOeTC0LHJYy/XVgYvT4B8ADMcuuAk5PmXY5sCLmdhuwGRiSst4/p0wvAbZEj08DPgAsZfprwC31LHsc8H7K81eBC+spWwpUpL12U6PHlwHPRY8vBV5KKdcOWFtdNsNyJwLzU56XA6NTnte8Z8AAwhdOl5TpdwD3NfbaNOF1/gfw+QzlvgKU5frzsD8NatELhGCrYWajzOy5qMthEyGEejUw/z9THm8jZb8AgLs3OD1m2cPT6lmrzunM7Ntm9n9R/TcQfmmkbkP6erpEj48AyqtTMbKygVX9BegRdfcMBIYQfgVgZl3M7L6o++sT4G80/DpWO4KU7XP3KkJ4V2/bYWb2iJmtjpb7QMzlVi/7Y3ffmjJuJZDapVTfa1NHI69zP0LYp+sH1LufSFqegl4gtKRTzQEeA/q5e3fgPlL6iHPkn0DflOf96itoZp8jdB99mdBl0JPQHRVnG9amrQdC10tG7l4J/Deh++ZC4A8pIfptQgt6pLsfRPi1EMdaUrbPzNql1ek/gJ3AcdFyp1J72xq6JO0aoJeZpYZ3IbA6Zt1qxHidPwAGZpi1vvHSShT0kkk3YL277zCzE4FJua4Q8AhwvZn1MLO+wDcaKNsNqAQ+BtoDt9BAqzTNS0A7M/tmtDPxPKDenZGR3xL6ui+MHqfWYxuwwcwOAW6KWYcngWFmdraZHQBcDfROW+5WYJOZ9QOuTZv/Q0K/fR3uvhwoA35oZh3NbBhwCTArZt1SNfY63wf8wMwGWjDMwo76uUBh9Bp3MLODzGxkE9YvMSnoJZMrgNvNbDNwPSFkc+1mQoCtAP6HUKed9ZR9itClsiQq/wmhldwod98JfAn4GqEr4lzCDteG/J0QeL2julX7T8IO7XVRmXpPiEqrw4eEL447onkLCX3/1W4GRgKbCKH5WNoifkjYkb3RzL6VYRUXAIMIv5IeBa5393lx6pamsdf5DsJr99do2kygk7tvAs4k/BL4CHgfSN0ZLC3MandFiuQHM7sSOMfdT891XUTaOrXoJS+YWR8z+4yZtTOzTxG6Mx7Pdb1E8oHOjJV80ZFwTHoRoUtlNnBPLiskki/UdSMiknDquhERSbg213XTq1cvLyoqynU1RETyyoIFCz52996ZprW5oC8qKqKsrCzX1RARyStmVu8Z3Oq6ERFJOAW9iEjCKehFRBKuzfXRZ7J7927Ky8vZsWNHrqsiDejUqRN9+/alffv2ua6KiKTIi6AvLy+nW7duFBUVYZbriyhKJu7OunXrKC8vZ8CAAbmujoikyIuumx07dnDIIYco5NswM+OQQw7Rry5JvFmzoKgI2rULf2c15bqf+1heBD2gkM8Deo8kn8UJ8FmzYNo0WLkS3MPfadOaH/at/eWRN0EvItJa4gb4DTfAtm21x23bFsbXt9xcfXmkUtDHsG7dOoYNG8awYcM47LDD6NOnT83zXbt2xVrGJZdcwnvvvdek9X/wwQdccMEFTZpXRBoXN8BXrco8f6bxrfXl0SS5vmlt+nD88cd7usWLF9cZ15CHH3bv39/dLPx9+OGsZm/QzTff7HfccUed8VVVVb5nz56WW1Geyva9EmmKlv6Mm7mHOK49mNUu179/5nL9+9ddZtyycdfdGBq44XriWvT74mdQtaVLl1JcXMzll1/OiBEjWLt2LdOmTaO0tJQhQ4YwY8aMmrInn3wyb775JpWVlfTo0YPp06czdOhQRo0axUcffQTARRddxFVXXcVnPvMZjjzySB5//PGa9QwbNgyA++67j4kTJzJ27FgGDRrEd7/73Zp13HPPPRx99NGMHj2ayy67jG99q+7NhV555RVGjRrF8OHDOemkk1iyZAkAlZWVXH311RQXF1NSUsLdd98NwKuvvsqoUaMYOnQoJ5xwAtvSmx4i+1g2n/G4fd+F9dwVOH38bbdB5861x3XuHMani9v6j7vuZqnvGyBXQ3Nb9Nl84zZFaot+yZIlbmb+2muv1Uxft26du7vv3r3bTz75ZF+0aJG7u5900kn+xhtv+O7dux3wp556yt3dr776ar/99tvd3X3KlCk+adIkr6qq8oULF/oxxxxTs56hQ4e6u/u9997rRx11lH/yySe+bds279u3r69evdpXrVrlRUVFvn79et+5c6ePGjXKr7rqqjr137hxo1dWVrq7+9NPP+3nn3++u7v//Oc/9/PPP79m2rp163z79u1eVFTkCxYsqDNvfdSil6aK20qP+xl/+GH3zp1rl+ncOfNysy2bq3o2hP2pRZ9NH1pLGDhwIJ/+9Kdrns+ePZsRI0YwYsQI3n33XRYvXlxnngMPPJDx48cDcPzxx7NixYqaaeeccw5mRklJCatXr864zjPOOINu3bpx4IEHcuyxx7Jq1SpeffVVTjvtNHr27EmHDh2YOHFixnk3btzIueeeS3FxMddeey2LFi0C4C9/+QuXX345BQUFABx88MG8++67FBYWMmJEuDd29+7da6ZLMuXq0MFsWulxP+PZ9H1PmQIzZ0L//mAW/s6cGcZnKrtiBVRVhb+ZykD81n82626qxAX9PvkZlKJLl703vV+yZAl33XUXf/vb33jrrbcYN25cxuPKO3ToUPO4oKCAysrKmucdO3aseRy+pOtKLVM9f31l091www2MHTuWd955hyeeeKKmfu5e5/DITOMkuVqjSyRu2WxCOe5nPNtGX9wAj6s1vjyaKnFBn00fWkv75JNP6NatGwcddBBr167lmWeeaf2VRk444QTmzZvHxo0b2b17N7///e8zltu0aRN9+vQB4IEHHqgZP2bMGH71q1+xZ88eANavX8+QIUNYuXIlr7/+OhC2r3q6JE/csM32CyFO2WxCOe5nfF83+jJp7QCPK3FBvy9+BtVnxIgRDB48mOLiYr72ta9x0kkntf5KI4WFhVx33XWMHDmSMWPGMGTIELp3716n3He+8x2uu+66OnX7+te/zmGHHUZJSQlDhw7lkUceoWPHjsyePZsrrriCoUOHMmbMGHbu3LmvNkn2sdboEolbNptQjvsZz2Wjr82pr/M+V0NLHF65v9q8ebO7u+/atcvHjx/vc+fO3ed10HvV9rT0zsNsDgeMW7aldkg2dduTgP1pZ+z+7Hvf+x7Dhw+npKSEY445hi984Qu5rpLkWDbdLK3RJRK3bGv9Em8rXSc5V983QK4Gtejzm96rfSdOazXbw43jLLO1DluU5qGBFn2s8AXGAe8BS4HpGab3B/4KvAU8B/RNmbYHeDMa5ja2LgV9ftN71TxxuxriBmhLnXXZ1HpmW1aarllBDxQA/wCOBDoAC4HBaWX+G7g4enwa8FDKtC2NrSN1UNDnN71XTZdN6zduS721TyCUtqOhoI/TRz8SWOruy9x9FzAHODutzOCoRQ8wL8N0kcRp6ZOLsjmaJe4RMjryRCDe4ZV9gA9SnpdH41ItBL4cPf4S0M3MDomedzKzMjN7xczOybQCM5sWlSmrqKjIovoiuZHtNZXifClkcyx5rndySn6JE/SZTo1MPw3zWuBUM3sDOBVYDVSf7lno7qXAhcCdZjawzsLcZ7p7qbuX9u7dO37t95HRo0fXOfnpzjvv5N/+7d8anK9r164ArFmzpt5LEowePZqysrIGl3PnnXfWupjYhAkT2LhxY5yqSxO09Jmccb8UsjmaJZuWuo48kTh99KOAZ1Kefxf4bgPluwLl9Ux7AJjY0PraYh/9r3/9a586dWqtcSeccIK/8MILDc7XpUuXRpd96qmn+vz58xss079/f6+oqGi8om1Art+r5mqNnZytdXEr7eSUVDRzZ+wBwDJgAHt3xg5JK9MLaBc9vg2YET3uCXRMKbOEtB256UNbDPqPP/7Ye/Xq5Tt27HB39+XLl3u/fv28qqrKN2/e7KeddpoPHz7ci4uL/YknnqiZrzroly9f7kOGDHF3923btvkFF1zgxx13nJ9//vk+cuTImqC//PLL/fjjj/fBgwf7TTfd5O7ud911l7dv396Li4t99OjR7l47+H/605/6kCFDfMiQIf6zn/2sZn3HHnusX3bZZT548GA/88wzfdu2bXW2a+7cuT5y5EgfNmyYn3766f7Pf/7T3cOJV1OnTvXi4mI/7rjj/NFHH3X3cLXL4cOHe0lJiZ922mkZX6tcv1f1aemThrLZyZnNl4LCW5qqWUEf5mcC8D7h6JsbonEzgLOixxOjEH8fuC8l3D8DvB19ObwN/Gtj62os6K+6yv3UU1t2yHA13zomTJhQE+K33367X3vtte4eLke8adMmd3evqKjwgQMHelVVlbtnDvqf/vSnfskll7i7+8KFC72goKAm6KsvcVxZWemnnnqqL1y40N3rtuirn5eVlXlxcbFv2bLFN2/e7IMHD/bXX3/dly9f7gUFBf7GG2+4u/t5553nDz30UJ1tWr9+fU1d7733Xr/mmmvc3f3b3/52rUscr1+/3j/66CPv27evL1u2rFZd07XFoM+mpdwaZ3LqyBfZFxoK+lhnxrr7U+5+tLsPdPfbonE3ufvc6PGj7j4oKnOZu++Mxv/d3Y9z96HR3/vjrK8tmjx5MnPmzAFgzpw5TJ48GQhflNdffz0lJSWcccYZrF69mg8//LDe5bzwwgtcdNFFAJSUlFBSUlIz7ZFHHmHEiBEMHz6cRYsWZbzEcaqXXnqJL33pS3Tp0oWuXbty7rnn8uKLLwIwYMCAmpuVpF8KuVp5eTljx47luOOO44477qh1yeJvfOMbNeV69uzJK6+8wmc/+1kGDBgAhMsY54vWuDJiNjs5deSL5NoBua5Atu68MzfrPeecc7jmmmt4/fXX2b59e8012mfNmkVFRQULFiygffv2FBUVZbw0capMl/5dvnw5P/nJT5g/fz49e/Zk6tSpjS4nfIlnln4p4+3bt9cpc+WVV3LNNddw1lln8dxzz3HLLbfULDdJlyzO9sqI06bV/mJoaCdnnB2b1WVuuCGss7AwLE87RWVf0bVuYuratSujR4/m0ksvrWnNQ7js76GHHkr79u2ZN28eK1eubHA5n/3sZ5kVHW7xzjvv8NZbbwHhEsBdunShe/fufPjhhzz99NM183Tr1o3NmzdnXNYTTzzBtm3b2Lp1K48//jinnHJK7G1KvWTxgw8+WDN+zJgx/OIXv6h5vmHDBkaNGsXzzz/P8uXLgXAZ43zRGldGzJaOfJFcUtBnYfLkySxcuJBJkybVjJsyZQplZWWUlpYya9Ysjj322AaXccUVV7BlyxZKSkr48Y9/zMiRIwEYOnQow4cPZ8iQIVx66aW1LiM8bdo0xo8fz+c+97layxoxYgRTp05l5MiRnHDCCVx22WUMHz489vbccsstnHfeeZxyyin06tWrZvyNN97Ihg0bKC4uZujQocybN4/evXszc+ZMzj33XIYOHcoFF1wQez25lm3XiUJZEqe+zvtcDW3xqBuJryXeq9a4joqOZpGko4GdsXnXRy/JVn1yUXUfefXJRVC3ZZ1N2bj96SJJpK4b2Wda+ozTbMqK7M/ypkXveXzUx/7CGzgKKG7rO5sjZLK9+bPI/iovWvSdOnVi3bp1DQaJ5Ja7s27dOjp16pRxemvcO7Qt3PxZJB/kRYu+b9++lJeXoytbtj1bt8KGDbB7N6xe3Ylu3foSnVNVSzaX1Y17HHs2ZUX2a/Xtpc3VkOmoG9n3WvqWctlcBkB3LxLJHg0cdWPexrpDSktLvbHL9krrSu9Ph9BSTj9xqKgo9LWn698/HH/elGWKSNOY2QIPl4SvIy/66GXfitufns3OUN0AQyR38qKPXvatuAFeWJi5RV/fzlAdyy6SG2rRSx1xj2bRVRlF8oOCfj8S92bWcQNc3TEi+UFdN/uJbC8XAPEuq6vuGJG2T0fd7CeyOUJGRPKPjrpJuDhdMrpcgMj+S0Gf56q7ZFauDKcgVXfJpIe9Lhcgsv9S0Oe5uMe86wgZkX1v1y547DF49dVwmZBc0c7YPBe3S0b3Lc0P7vDhh7B5M/TrB/VcIy4v7NkDr7wCf/oTvPQS9OgR/u/Sh8MPh4KCXNe25W3fDhMnwlNPhecHHggnnggnnxyGE0+Egw7aN3WJtTPWzMYBdwEFwH3u/qO06f2B3wC9gfXARe5eHk27GLgxKvoDd3+QBmhnbHa0kzV/bd0K77wDb79de/j4471l/uVfModj9dC7dzi0ta1Yvx6eeSaE+9NPh+cFBfDpT4fgW7UqXAQv1QEHQJ8+e7fp4IPjbVNBARx1FBx3XBh69GidbWqKTz6BL34RXnwRfvazsH0vvhi+8N58M9ymsl07GDoUTjllb/gffnjT19nQzthGg97MCoD3gTOBcmA+MNndF6eU+W/gSXd/0MxOAy5x96+Y2cFAGVAKOLAAON7dN6Svp5qCPpg1K17rW9eQadiePTB/fgieP/0J1qwJLeX6gvPQQ1s2OKuq4KOPwvu4YkXtYF+2LLTgIbxnxcUhsEpKoHt3+OCD8CW+atXeIb2brkOHMLSkdu3gsMPqf41Sf2m4h22qfn3//vewzb16wYQJ8PnPw5gxtUN48+bM27ZqVRi3aVO8eu7aVfv16Ns3vHbVwX/ccXDssbVfn127YPXqzOtdtQo2boRrr4VvfSu8Dk3x8ccwfnwI9P/6L5g8ufb0zZvDL52XXgrh/8or4UsQYPRomDevaettbtCPAm5x97HR8+8CuPvtKWUWAWPdvdzC3UE2uftBZjYZGO3uX4/K3QM85+6z61ufgj778I77pRCXe/jH27IFevaE9u2bvqxc2LgR/ud/QvA89VT44LVrByedBMccE0Km+gO+dWvteTt2DEHWrx8cckgI3MaGysq9y0wPrw8+COFSrV07GDRob6BXB9KAAY0Hi3toIaeG0+rVYf0tqbIS1q7du561a+uWOfTQ8L9W/SUGMHx4CPbPfz604Fu7O8Ydysvr/iJ69929/eEHHBDe827d9m5LeuRVb0thYfiS+etf4fTT4YEHwpdHNtasgTPPhH/8Ax59FL7whcbn2b0b3ngjBH9BAVx1VXbrrNbcoJ8IjHP3y6LnXwFOcPdvppT5LfCqu99lZucCjwG9gEuATu7+g6jc94Dt7v6T+tanoG+97phNm0IAvv12eJxp2Lgx/K0Oj3bt4Igjarfo+vev/bx795ZtBbvDX/4S/vkPOihzuPboAV27hvW6w//9Xwj2J58MH5g9e0IXwPjxIXjGjg3P09ezYUPd1l11QG/YsPf1SG9J1yfT65U6HH106KvNJzt31t8K7tIlvMYTJoTuibZg9254/31466294b99e+b/3b59a78f7nD//SFsO3aEe+6B886Lt95ly+CMM6CiAubOhc99rnW2rz7NDfrzCK311KAf6e5XppQ5AvgFMAB4AfgyMASYBnRMC/pt7v7TtHVMi8pSWFh4/MpMKbcfadeubqsDQqhVVcVfjju8997en9UvvhgC3Kz+AE0dunYN/7SprdT0FiqE1tKwYfC1r4UPRVN3IO7ZA7//PfzoR/D6642Xb9cubEf79qGeEFrJ1a3KE09suVbl7t2h3zXTl2NBwd7gOOKI/PsFJHUtWQIXXQSvvQYXXww//3nDO04XLw4t+R07wr6JkSP3XV2rNRT0cY66KQf6pTzvC6xJLeDua4Bzo5V1Bb7s7pvMrBwYnTbvc+krcPeZwEwILfoYdUqsXbtC/2h9P5eXLw8tp/r6ZXfuhOef39u6XbYsjC8uhn//9/BT8sQTw0/apkjtc05t2f35z/DVr8LVV8Oll8LXvw4DB8Zb5s6doS/zxz+GpUtDq/f+++Hcc0NLur5fH9XD1q2hq2DChNY7L6B9+9CVc8ghrbN8aVsGDQq/DL///dAV+sIL8NBDofsvXVkZjBsX/keefz581tqc+u5IUj0QvgyWEVrrHYCFwJC0Mr2AdtHj24AZ0eODgeVAz2hYDhzc0Pr2lztMVVW5r1jhPneu+223uU+a5D5kiPsBB2S+E1PqYObep4/7qFHuF1zgft117v/xH+5nn+3epUso06mT++c/73733WE9+2J7/vpX9y9/2b2gINRh7Fj3J55w37078zyffOJ+xx3uhx8eyh9/vPujj7pXVrZ+fUXi+t//dR8wwL1dO/cbb3TftWvvtOefd+/Wzb2oyH3p0tzV0b3hO0zFur0fMIFw5M0/gBuicTOAs6LHE4ElUZn7CN011fNeCiyNhksaW1fSg/7tt93POMP9oIPq3lLvi190v/5699mz3X/0I/fCwhDq/fqFQHz2Wff773e/+Wb3qVPdTzvN/aij3Dt0CMsoLHS/4gr3J59037o1d9tYXu5+yy3uRxwR6tWvn/v3v+++dm2Y/tFH4QPTo0eYfvrpYduqqnJXZ5GGbNoUPnPgPnKk+/vvu//pT6FB9alPhf/5XGso6HVRs32kqir0802fHvq/zztv7xEXxcXNO3GiqirsNOzZs20dU11ZCX/8I/zqV/Dss6G76NRTwyF4O3aErpnvfCd0u4jkg0cfDUfE7dwZullLSkK3Ze/eua5ZM3fG7mtJDPo1a2Dq1BB2X/wi3Hdf6G/fnyxZAr/+NTz+eDga4brrwjHOIvlm9eqwD6qyEn73u9BwawsU9Dn02GOhBbBjRzhDrnNnuPFGXYZARFqWLlOcA5s3h6NPJk6EI48Mx4R36RJaAo1daVJEpCUp6BuxZEnms+ka8vLL4bjyBx8MZ6z+/e/hkMG4V5oUEWlJunplA956K5zWXVUVjp9Ov47GkCHhpKJqlZXwgx+EoV+/cEztySfvna6bf4hILijoGzBjRgjyW2+FRYvCqdT331/7+ihHHrk3+J99Nlx3+qtfDUfYpO+kKSzMfGkD3fxDRFqTgr4eb70VdqTedFO4kl21qqpwdmr6hZT++MdwiOTvfgfnn595mbfdlvliZbr5h4i0JgV9PW69NQR3ashDuL7KwIFhOOecveN37Ah/G7rOi27+ISK5oKDPYOHCcHGtm24KJyHFEfdCXlOmKNhFZN/SUTcZzJiRuTUvIpKPFPRpqlvz3/pW/Na8iEhbpqBPM2NGOFrm6qvjzzNrVrhZSLt24a9OgBKRtkR99CmqW/M33xz/RsPpt/2rPtsV1BcvIm2DWvQpqlvz2fTN62xXEWnrFPSRN9/c2zcftzUPOttVRNo+BX2kKa15qP+sVp3tKiJthYKe0Jp//PHsW/MQTnjq3Ln2OJ3tKiJtiYKeprfmIexwnTkT+vcPd3fq3z88145YEWkr9vujbqpb89kcaZNOZ7uKSFu237fom9OaFxHJB/t10Denb15EJF/s10F/660Nt+Z1xquIJEGsoDezcWb2npktNbPpGaYXmtk8M3vDzN4yswnR+CIz225mb0bDr1t6A5rqjTfgiSfCpQ4ytearz3jV/V1FJN+ZN3IzVDMrAN4HzgTKgfnAZHdfnFJmJvCGu//KzAYDT7l7kZkVAU+6e3HcCpWWlnpZWVnWG5KtL30J5s2DFSsyB31RUea7QfXvH+YREWlLzGyBu5dmmhanRT8SWOruy9x9FzAHODutjAMHRY+7A2uaWtl9obHWPOiMVxFJjjhB3wf4IOV5eTQu1S3ARWZWDjwFXJkybUDUpfO8mZ2SaQVmNs3MysysrKKiIn7tm+Cdd+DLXw4Bf9VV9ZfTGa8ikhRxgt4yjEvv75kMPODufYEJwENm1g5YCxS6+3DgGuC3ZnZQ2ry4+0x3L3X30t69e2e3BVmYOxdGjQq3/fvznxs+0kZnvIpIUsQJ+nKgX8rzvtTtmvlX4BEAd38Z6AT0cved7r4uGr8A+AdwdHMrnS13uP32cI/XY4+F+fPhhBMankdnvIpIUsQJ+vnAIDMbYGYdgEnA3LQyq4DTAczsU4SgrzCz3tHOXMzsSGAQsKylKh/H9u0hnEzRyqAAAAy+SURBVK+/HiZNghdegD7pHU/1mDIl7Hitqgp/FfIiko8avQSCu1ea2TeBZ4AC4DfuvsjMZgBl7j4X+HfgXjO7mtCtM9Xd3cw+C8wws0pgD3C5u69vta1Js3o1nH02vP46/PCHMH16aJ2LiOxPGj28cl9rqcMrX301dNVs2RKOfT/rrBaonIhIG9XcwyvzzsMPw6mnwoEHwssvK+RFZP+WqKDfswe+/W34ylfC0TWvvQbFsU/VEhFJpsRcpviTT+DCC+FPf4IrroC77oL27XNdKxGR3EtM0G/ZEk6GuvvuEPQiIhIkJuiPOALefTf0y4uIyF6J6qNXyIuI1JWooBcRkboU9CIiCaegFxFJOAW9iEjCKehFRBJOQS8iknAKehGRhFPQi4gknIJeRCThFPQiIgmnoBcRSTgFvYhIwinoRUQSTkEvIpJwCnoRkYRT0IuIJFysoDezcWb2npktNbPpGaYXmtk8M3vDzN4yswkp074bzfeemY1tycqLiEjjGg16MysAfgmMBwYDk81scFqxG4FH3H04MAm4O5p3cPR8CDAOuDtaXs7MmgVFRdCuXfg7a1YuayMi0vritOhHAkvdfZm77wLmAGenlXHgoOhxd2BN9PhsYI6773T35cDSaHk5MWsWTJsGK1eCe/g7bZrCXkSSLU7Q9wE+SHleHo1LdQtwkZmVA08BV2YxL2Y2zczKzKysoqIiZtWzd8MNsG1b7XHbtoXxIiJJFSfoLcM4T3s+GXjA3fsCE4CHzKxdzHlx95nuXurupb17945RpaZZtSq78SIiSRAn6MuBfinP+7K3a6bavwKPALj7y0AnoFfMefeZwsLsxouIJEGcoJ8PDDKzAWbWgbBzdW5amVXA6QBm9ilC0FdE5SaZWUczGwAMAl5rqcpn67bboHPn2uM6dw7jRUSSqtGgd/dK4JvAM8C7hKNrFpnZDDM7Kyr278DXzGwhMBuY6sEiQkt/MfBn4Bvuvqc1NiSOKVNg5kzo3x/Mwt+ZM8N4EZGkMvc6XeY5VVpa6mVlZbmuhohIXjGzBe5emmmazowVEUk4Bb2ISMIp6EVEEk5BLyKScAp6EZGEU9CLiCScgl5EJOEU9CIiCaegFxFJOAW9iEjCKehFRBJOQS8iknAKehGRhFPQi4gknIJeRCThFPQiIgmnoBcRSTgFvYhIwinoRUQSTkEvIpJwCnoRkYRT0IuIJFysoDezcWb2npktNbPpGab/zMzejIb3zWxjyrQ9KdPmtmTlRUSkcQc0VsDMCoBfAmcC5cB8M5vr7oury7j71SnlrwSGpyxiu7sPa7kqi4hINuK06EcCS919mbvvAuYAZzdQfjIwuyUqJyIizRcn6PsAH6Q8L4/G1WFm/YEBwN9SRncyszIze8XMzqlnvmlRmbKKioqYVRcRkTjiBL1lGOf1lJ0EPOrue1LGFbp7KXAhcKeZDayzMPeZ7l7q7qW9e/eOUSUREYkrTtCXA/1SnvcF1tRTdhJp3Tbuvib6uwx4jtr99yIi0sriBP18YJCZDTCzDoQwr3P0jJkdA/QEXk4Z19PMOkaPewEnAYvT5xURkdbT6FE37l5pZt8EngEKgN+4+yIzmwGUuXt16E8G5rh7arfOp4B7zKyK8KXyo9SjdUREpPVZ7VzOvdLSUi8rK8t1NURE8oqZLYj2h9ahM2NFRBJOQS8iknAKehGRhFPQi4gknIJeRCThFPQiIgmnoBcRSTgFvYhIwinoRUQSTkEvIpJwCnoRkYRT0IuIJJyCXkQk4RT0IiIJp6AXEUk4Bb2ISMIp6EVEEk5BLyKScAp6EZGEU9CLiCScgl5EJOEU9CIiCRcr6M1snJm9Z2ZLzWx6huk/M7M3o+F9M9uYMu1iM1sSDRe3ZOVFRKRxBzRWwMwKgF8CZwLlwHwzm+vui6vLuPvVKeWvBIZHjw8GbgZKAQcWRPNuaNGtEBGResVp0Y8Elrr7MnffBcwBzm6g/GRgdvR4LPCsu6+Pwv1ZYFxzKiwiItmJE/R9gA9SnpdH4+ows/7AAOBv2cxrZtPMrMzMyioqKuLUW0REYooT9JZhnNdTdhLwqLvvyWZed5/p7qXuXtq7d+8YVRIRkbjiBH050C/leV9gTT1lJ7G32ybbeUVEpBXECfr5wCAzG2BmHQhhPje9kJkdA/QEXk4Z/Qwwxsx6mllPYEw0TkRE9pFGj7px90oz+yYhoAuA37j7IjObAZS5e3XoTwbmuLunzLvezL5P+LIAmOHu61t2E0REpCGWksttQmlpqZeVleW6GiIiecXMFrh7aaZpOjNWRCThFPQiIgmnoBcRSTgFvYhIwinoRUQSTkEvIpJwCnoRkYRT0IuIJJyCXkQk4RT0IiIJp6AXEUk4Bb2ISMIp6EVEEk5BLyKScAp6EZGEU9CLiCScgl5EJOEU9CIiCaegFxFJOAW9iEjCKehFRBIuMUE/axYUFUG7duHvrFm5rpGISNsQK+jNbJyZvWdmS81sej1lzjezxWa2yMx+mzJ+j5m9GQ1zW6riqWbNgmnTYOVKcA9/p01T2IuIAJi7N1zArAB4HzgTKAfmA5PdfXFKmUHAI8Bp7r7BzA5194+iaVvcvWvcCpWWlnpZWVlWG1FUFMI9Xf/+sGJFVosSEclLZrbA3UszTYvToh8JLHX3Ze6+C5gDnJ1W5mvAL919A0B1yO8rq1ZlN15EZH8SJ+j7AB+kPC+PxqU6GjjazP7XzF4xs3Ep0zqZWVk0/pxMKzCzaVGZsoqKiqw2AKCwMLvxIiL7kzhBbxnGpff3HAAMAkYDk4H7zKxHNK0w+jlxIXCnmQ2sszD3me5e6u6lvXv3jl35arfdBp071x7XuXMYLyKyv4sT9OVAv5TnfYE1Gcr8wd13u/ty4D1C8OPua6K/y4DngOHNrHMdU6bAzJmhT94s/J05M4wXEdnfxQn6+cAgMxtgZh2ASUD60TNPAJ8DMLNehK6cZWbW08w6pow/CVhMK5gyJex4raoKfxXyIiLBAY0VcPdKM/sm8AxQAPzG3ReZ2QygzN3nRtPGmNliYA9wnbuvM7PPAPeYWRXhS+VHqUfriIhI62v08Mp9rSmHV4qI7O+ae3iliIjkMQW9iEjCKehFRBKuzfXRm1kFkH5Bg17AxzmoTmtK2jYlbXsgeduUtO2B5G1Tc7anv7tnPBGpzQV9JmZWVt9OhnyVtG1K2vZA8rYpadsDydum1toedd2IiCScgl5EJOHyJehn5roCrSBp25S07YHkbVPStgeSt02tsj150UcvIiJNly8tehERaSIFvYhIwrX5oI9zv9p8YmYrzOzt6B66eXlRHzP7jZl9ZGbvpIw72MyeNbMl0d+euaxjNurZnlvMbHXK/Y4n5LKO2TKzfmY2z8zeje7jfFU0Pi/fpwa2J2/fJzPrZGavmdnCaJtujcYPMLNXo/fod9FVg5u3rrbcRx/nfrX5xsxWAKXunrcneZjZZ4EtwH+5e3E07sfAenf/UfSF3NPdv5PLesZVz/bcAmxx95/ksm5NZWaHA4e7++tm1g1YAJwDTCUP36cGtud88vR9MjMDurj7FjNrD7wEXAVcA/ze3eeY2a+Bhe7+q+asq6236OPcr1b2MXd/AVifNvps4MHo8YOED2FeqGd78pq7r3X316PHm4F3CbcAzcv3qYHtyVsebImeto8GB04DHo3Gt8h71NaDPs79avONA/9jZgvMbFquK9OC/sXd10L4UAKH5rg+LeGbZvZW1LWTF10cmZhZEeHObq+SgPcpbXsgj98nMyswszeBj4BngX8AG929MirSIpnX1oM+zv1q881J7j4CGA98I+o2kLbnV8BAYBiwFvhpbqvTNGbWFXgM+Ja7f5Lr+jRXhu3J6/fJ3fe4+zDCLVpHAp/KVKy562nrQR/nfrV5JeUeuh8BjxPe3CT4MOpHre5P/SjH9WkWd/8w+hBWAfeSh+9T1O/7GDDL3X8fjc7b9ynT9iThfQJw942Ee2qfCPQws+q7/7VI5rX1oI9zv9q8YWZdoh1JmFkXYAzwTsNz5Y25wMXR44uBP+SwLs1WHYaRL5Fn71O0o+9+4F13/8+USXn5PtW3Pfn8PplZbzPrET0+EDiDsO9hHjAxKtYi71GbPuoGIDpc6k723q/2thxXqcnM7EhCKx7C/Xp/m4/bY2azgdGES6p+CNxMuEH8I0AhsAo4z93zYgdnPdszmtAd4MAK4OvVfdv5wMxOBl4E3gaqotHXE/q18+59amB7JpOn75OZlRB2thYQGt2PuPuMKCfmAAcDbwAXufvOZq2rrQe9iIg0T1vvuhERkWZS0IuIJJyCXkQk4RT0IiIJp6AXEUk4Bb2ISMIp6EVEEu7/A9pnJ6yGdGuiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label = 'Trainning acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title(' Trainning and validation acc')\n",
    "plt.legend()\n",
    "plt.figure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 16,812,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# convnet model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable weights before freezing: 30\n",
      " trainable weights after freezing 4\n"
     ]
    }
   ],
   "source": [
    "# freeze the layer so that weights arent updated during training, due to large number of parameters\n",
    "print('Trainable weights before freezing:', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('Trainable weights after freezing', len(model.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/2\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.7010 - accuracy: 0.5400 - val_loss: 0.7004 - val_accuracy: 0.5500\n",
      "Epoch 2/2\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.6969 - accuracy: 0.5300 - val_loss: 0.6979 - val_accuracy: 0.4750\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "\n",
    "train_dataget = ImageDataGenerator(rescale = 1./255,     # data augmentation, transformin image leads to more data,\n",
    "                                            # no specific values, randomly applied to transform, reduce overfitting\n",
    "                                  rotation_range = 40,\n",
    "                                  width_shift_range = 0.2,\n",
    "                                  height_shift_range = 0.2,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = 'nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size = (150, 150), # resize image to 150 X 150\n",
    "                                                   batch_size = 20,\n",
    "                                                   class_mode = 'binary')\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size = (150, 150),\n",
    "                                                       batch_size = 20,\n",
    "                                                       class_mode = 'binary')\n",
    "\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = optimizers.RMSprop(lr = 2e-5),\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = 5,\n",
    "                             epochs = 2,\n",
    "                             validation_data = validation_generator,\n",
    "                             validation_steps = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
